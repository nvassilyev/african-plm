{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/opc/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "# from swissdox import SwissdoxData\n",
    "import tokenization\n",
    "# import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANGUAGES = [\n",
    "#     \"de_CH\",\n",
    "#     \"fr_CH\",\n",
    "#     \"it_CH\",\n",
    "#     \"rm_CH\",\n",
    "# ]\n",
    "\n",
    "language = \"yo_XX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data\")\n",
    "assert data_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir_xlm_vocab = data_dir / \"xlm_vocab\"\n",
    "out_dir_xlm_vocab.mkdir(exist_ok=True)\n",
    "out_dir_new_vocab = data_dir / \"new_vocab\"\n",
    "out_dir_new_vocab.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization with XLM vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# for language in LANGUAGES:\n",
    "for txt_path in [\n",
    "    out_dir_xlm_vocab / \"train.txt\",\n",
    "    out_dir_xlm_vocab / \"valid.txt\"\n",
    "]:\n",
    "    tokenization.tokenize_xlm(\n",
    "        txt_path,\n",
    "        txt_path.with_suffix(f\".xlm.bpe\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization with new vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenization.create_spm_vocabulary(\n",
    "    txt_paths=[out_dir_new_vocab / f\"{language}.train.txt\"],\n",
    "    name=\"swissbert\",\n",
    "    sampling_alpha=0.3,\n",
    "    vocab_size=50260,\n",
    "    # user_defined_symbols=[\"</s>\", \"<medium>\", \"<year>\", \"<month>\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\"spm.yoruba.model\")\n",
    "vocab_path = Path(\"spm.yoruba.vocab\")\n",
    "assert model_path.exists()\n",
    "assert vocab_path.exists()\n",
    "vocab_dir = Path(\"../vocab\")\n",
    "assert vocab_dir.exists()\n",
    "shutil.move(model_path, vocab_dir / model_path.name)\n",
    "shutil.move(vocab_path, vocab_dir / vocab_path.name)\n",
    "swissbert_model_path = vocab_dir / model_path.name\n",
    "swissbert_vocab_path = vocab_dir / vocab_path.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268051\n",
      "['<s>', '<pad>', '</s>', '<unk>', ',', '.', '▁', 's', '▁de', '-']\n",
      "268051\n",
      "['<s>', '<pad>', '</s>', '<unk>', ',', '.', '▁', 's', '▁de', '-']\n"
     ]
    }
   ],
   "source": [
    "# for language in LANGUAGES:\n",
    "tokenizer = Path(\"../tokenizer\")\n",
    "for txt_path in [\n",
    "    out_dir_new_vocab / \"train.txt\",\n",
    "    out_dir_new_vocab / \"valid.txt\"\n",
    "]:\n",
    "    tokenization.tokenize_hf(\n",
    "        tokenizer,\n",
    "        txt_path,\n",
    "        txt_path.with_suffix(f\".new.bpe\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"DATA_DIR\"] = str(out_dir_xlm_vocab.resolve())\n",
    "# for language in LANGUAGES:\n",
    "os.environ[\"LANGUAGE\"] = language\n",
    "!fairseq-preprocess \\\n",
    "  --only-source \\\n",
    "  --trainpref \"$DATA_DIR/train.xlm.bpe\" \\\n",
    "  --validpref \"$DATA_DIR/valid.xlm.bpe\" \\\n",
    "  --destdir \"$DATA_DIR/bin/$LANGUAGE\" \\\n",
    "  --bpe sentencepiece \\\n",
    "  --srcdict ../vocab/xlm.dict.txt \\\n",
    "  --workers 20\n",
    "!rm \"$DATA_DIR/bin/$LANGUAGE/dict.txt\"\n",
    "!cp ../vocab/xlm.dict.txt \"$DATA_DIR/bin/dict.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert spm vocab to fairseq format\n",
    "from transformers import XLMRobertaTokenizer\n",
    "swissbert_dict_path = Path(\"../tokenizer/yo.dict.txt\")\n",
    "vocab = XLMRobertaTokenizer.from_pretrained(\"../tokenizer\").get_vocab()\n",
    "# import json\n",
    "\n",
    "# with open(\"dict_dump.json\", \"w\") as f_out:\n",
    "#     json.dump(vocab, f_out)\n",
    "\n",
    "with open(swissbert_dict_path, \"w\") as f_out:\n",
    "    for token in vocab:\n",
    "        if token in {\"<s>\", \"<pad>\", \"</s>\", \"<unk>\"}:\n",
    "            continue\n",
    "        f_out.write(f\"{token} 1\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-13 15:09:39 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe='sentencepiece', optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang=None, target_lang=None, trainpref='/mnt/disk/african-plm/swissbert/data/yo_XX/new_vocab/train.new.bpe', validpref='/mnt/disk/african-plm/swissbert/data/yo_XX/new_vocab/valid.new.bpe', testpref=None, align_suffix=None, destdir='/mnt/disk/african-plm/swissbert/data/yo_XX/new_vocab/bin/yo_XX', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict='/mnt/disk/african-plm/swissbert/tokenizer/yo.dict.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=True, padding_factor=8, workers=20, dict_only=False)\n",
      "2023-07-13 15:09:39 | INFO | fairseq_cli.preprocess | [None] Dictionary: 268051 types\n",
      "2023-07-13 15:10:05 | INFO | fairseq_cli.preprocess | [None] /mnt/disk/african-plm/swissbert/data/yo_XX/new_vocab/train.new.bpe: 887299 sents, 51391669 tokens, 0.0255% replaced (by <unk>)\n",
      "2023-07-13 15:10:05 | INFO | fairseq_cli.preprocess | [None] Dictionary: 268051 types\n",
      "2023-07-13 15:10:07 | INFO | fairseq_cli.preprocess | [None] /mnt/disk/african-plm/swissbert/data/yo_XX/new_vocab/valid.new.bpe: 10000 sents, 426597 tokens, 0.00328% replaced (by <unk>)\n",
      "2023-07-13 15:10:07 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /mnt/disk/african-plm/swissbert/data/yo_XX/new_vocab/bin/yo_XX\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"DATA_DIR\"] = str(out_dir_new_vocab.resolve())\n",
    "os.environ[\"DICT_PATH\"] = str(swissbert_dict_path.resolve())\n",
    "# for language in LANGUAGES:\n",
    "os.environ[\"LANGUAGE\"] = language\n",
    "!fairseq-preprocess \\\n",
    "  --only-source \\\n",
    "  --trainpref \"$DATA_DIR/train.new.bpe\" \\\n",
    "  --validpref \"$DATA_DIR/valid.new.bpe\" \\\n",
    "  --destdir \"$DATA_DIR/bin/$LANGUAGE\" \\\n",
    "  --bpe sentencepiece \\\n",
    "  --srcdict \"$DICT_PATH\" \\\n",
    "  --workers 20\n",
    "# !rm \"$DATA_DIR/bin/$LANGUAGE/dict.txt\"\n",
    "# !cp $DICT_PATH \"$DATA_DIR/bin/dict.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from fairseq to huggingface format\n",
    "\n",
    "! python3 ../convert_xmod_original_pytorch_checkpoint_to_pytorch.py \\\n",
    "    --xmod_checkpoint_path ../models/swissbert_yo_new_vocab/checkpoint_last.pt\\\n",
    "    --pytorch_dump_folder_path ../../models/xmod_fairseq "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
